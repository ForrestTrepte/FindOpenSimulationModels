{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FindOpenSimulationModels\n",
    "\n",
    "An experiment to find simulation models such as FMU and Modelica files on the open internet. I am curious how prevalent they are and whether they have inputs and outputs that would be suitable for reinforcement learning environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# While developing, limit the amount of data that is downloaded.\n",
    "# Set to False when ready to download all the data.\n",
    "is_testing = True\n",
    "\n",
    "fmu_list_filename = 'results/github-fmu-search.txt'\n",
    "import importlib"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FMUs on GitHub\n",
    "\n",
    "Let's start by looking at FMU files that exist in GitHub repositories.\n",
    "\n",
    "### Manual search\n",
    "\n",
    "We can enter `extension:fmu` in the GitHub search box and choose `All GitHub', resulting in the query https://github.com/search?q=extension%3Afmu&type=code. This resulted in 10,841 code results. That's good that there are thousands of FMU files out there! However, we would need to hit the *Next* button to page through a few files at a time and manually copy their URLs from the web page.\n",
    "\n",
    "### GitHub API search\n",
    "\n",
    "Next, let's try doing this programmatically with the [GitHub search API](https://docs.github.com/en/rest/search). Unfortunately, this doesn't seem to be possible based on this [Reddit](https://www.reddit.com/r/github/comments/dr19uu/finding_all_files_with_a_certain_extension/) and [Stack Overflow](https://stackoverflow.com/questions/58673751/find-all-files-with-certain-filetype-on-github) discussion from three years ago. My results were the same.\n",
    "\n",
    "Here's what I tried (TLDR it didn't work):\n",
    "\n",
    "A **repository** search of `https://api.github.com/search/repositories?q=extension:fmu` only returns one result. It did indeed find a [repository](https://github.com/INTO-CPS-Association/distributed-maestro-fmu) that contains a [singlewatertank-20sim.fmu](https://github.com/INTO-CPS-Association/distributed-maestro-fmu/blob/95922d63eb50c17609320c180319f23d17173c7f/bundle/src/test/resources/singlewatertank-20sim.fmu) file. But there should be many more repositories. It seems that the extensions qualifier is doing something but--if it works--it is only scanning a small subset of GitHub.\n",
    "\n",
    "The [repository API doc](https://docs.github.com/en/rest/search?apiVersion=2022-11-28#search-repositories) says to see [Searching for repositories](https://docs.github.com/en/search-github/searching-on-github/searching-for-repositories) for a detailed list of qualifiers. In that documentation, [Search based on the contents of a repository](https://docs.github.com/en/search-github/searching-on-github/searching-for-repositories#search-based-on-the-contents-of-a-repository) states:\n",
    "\n",
    "> Besides using in:readme, it's not possible to find repositories by searching for specific content within the repository. To search for a specific file or content within a repository, you can use the file finder or code-specific search qualifiers.\n",
    "\n",
    "A **code** search of `https://api.github.com/search/code?q=extension:fmu` returns a `Validation Failed` error with `Must include at least one user, organization, or repository`. So it seems it is not possible to search all of GitHub in this way. In the documentation, [Considerations for code search](https://docs.github.com/en/rest/search?apiVersion=2022-11-28#considerations-for-code-search) states:\n",
    "\n",
    "> * Only files smaller than 384 KB are searchable.\n",
    "> * ...\n",
    "> * You must always include at least one search term when searching source code. For example, searching for language:go is not valid, while amazing language:go is.\n",
    "\n",
    "This will not work for FMU files because we want all of them (not just FMUs containing some particular search term), they are larger than 384 KB, and they are in a binary (zip) format that wouldn't work with a text search.\n",
    "\n",
    "In the [Reddit thread](https://www.reddit.com/r/github/comments/dr19uu/comment/f6ezx4e/?utm_source=share&utm_medium=web2x&context=3) OP Gasp0de also looked into using [GH Archive](https://www.gharchive.org/), but it it doesn't look like GH Archive includes an event type with file information about the contents of repositories/commits.\n",
    "\n",
    "### Scraping\n",
    "\n",
    "Based on the [Information Usage Restrictions](https://docs.github.com/en/site-policy/acceptable-use-policies/github-acceptable-use-policies#7-information-usage-restrictions), it appears that web scraping of GitHub is permitted:\n",
    "\n",
    "> You may use information from our Service for the following reasons, regardless of whether the information was scraped, collected through our API, or obtained otherwise:\n",
    "> \n",
    "> Researchers may use public, non-personal information from the Service for research purposes, only if any publications resulting from that research are open access.\n",
    "Archivists may use public information from the Service for archival purposes.\n",
    "\n",
    "We are researching the nature of FMU files that are present on GitHub with the intent to crate an archive or index of them, so that seems to fit. We don't expect it will be a tremendous amount of data and we won't be spamming anyone. Let's give it a try."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting: https://github.com/search?q=extension%3Afmu&type=code\n",
      "Result: status code = 200, url = https://github.com/login?return_to=https%3A%2F%2Fgithub.com%2Fsearch%3Fq%3Dextension%253Afmu%26type%3Dcode\n",
      "  <title>Sign in to GitHub Â· GitHub</title>\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "search_url = 'https://github.com/search?q=extension%3Afmu&type=code'\n",
    "print(f'Getting: {search_url}')\n",
    "search = requests.get(search_url)\n",
    "print(f'Result: status code = {search.status_code}, url = {search.url}')\n",
    "# print response lines containing the string <title>\n",
    "for line in search.text.splitlines():\n",
    "    if '<title>' in line:\n",
    "        print(line)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is requiring us to log in, so we won't just be able to get the results by fetching URLs. Let's try scraping the search results using browser automation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening: https://github.com/search?q=extension:fmu&type=code\n",
      "Use the web browser window to log in to GitHub...\n",
      "First page of search results loaded\n",
      "10,845 code results\n",
      "Found 100 pages of results\n",
      "Limiting to 3 pages in testing mode\n"
     ]
    }
   ],
   "source": [
    "# It is requiring us to log in, so we won't just be able to get the results by fetching URLs. Let's try scraping the search results using browser automation.\n",
    "import ScrapeGitHubFilesByExtension\n",
    "importlib.reload(ScrapeGitHubFilesByExtension) # reload changes to ScrapeGitHubFilesByExtension.py every run\n",
    "# Open browser and get ready to scrape search results\n",
    "scrape = ScrapeGitHubFilesByExtension.ScrapeGitHubFilesByExtension('fmu', fmu_list_filename, filter_out_private_repositories=True, is_testing=is_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done scraping 3 pages * 4 orders\n",
      "This scan has found 0 new FMUs, 109 already known FMUs, 1 FMUs from private repos (filtered out)\n",
      "The entire collection now has 3879 FMUs\n",
      "\n",
      "Retries:\n",
      "  succeeded after 0 retries: 9 pages\n",
      "  succeeded after 1 retries: 1 pages\n",
      "  failed: 0 pages\n"
     ]
    }
   ],
   "source": [
    "# Page through the search results to scrape a list of FMU URLs\n",
    "# Note that, during development, this cell can be run multiple times while the logged-in browser is still open.\n",
    "scrape.scrape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the browser\n",
    "del scrape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We weren't able to identify all of the 10,841 FMUs reported by GitHub search, but we do have several thousand. This is a good enough sampling that we will move on to take a look at these files to see if they would be suitable as reinforcement learning environments.\n",
    "\n",
    "### Downloading\n",
    "\n",
    "Next, let's download FMU files from the GitHub URLs we collected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "0 files downloaded, 2 failed, 2991 skipped (already cached)\n",
      "\n",
      "Errors:\n",
      "https://raw.githubusercontent.com/microsoft/FMU-bonsai-connector/937ce984d0896681132fde209ef06048f14a5850/samples/Integrator.fmu: 404 - 404: Not Found\n",
      "https://raw.githubusercontent.com/microsoft/FMU-bonsai-connector/937ce984d0896681132fde209ef06048f14a5850/samples/vanDerPol.fmu: 404 - 404: Not Found\n"
     ]
    }
   ],
   "source": [
    "import DownloadGitHubFiles\n",
    "importlib.reload(DownloadGitHubFiles) # reload changes to DownloadGitHubFiles.py every run\n",
    "download = DownloadGitHubFiles.DownloadGitHubFiles(fmu_list_filename, is_testing)\n",
    "download.download()\n",
    "del download"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "\n",
    "Now we can analyze our collection of FMU files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'type' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 14\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[0;32m      2\u001b[0m dtype \u001b[39m=\u001b[39m {\n\u001b[0;32m      3\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mFilename\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mstr\u001b[39m,\n\u001b[0;32m      4\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mValid\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mbool\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mGeneration Tool\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mstr\u001b[39m,\n\u001b[0;32m     13\u001b[0m }\n\u001b[1;32m---> 14\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mDataFrame(columns\u001b[39m=\u001b[39;49mdtype\u001b[39m.\u001b[39;49mkeys(), dtype\u001b[39m=\u001b[39;49mdtype)\n",
      "File \u001b[1;32mc:\\Users\\forre\\miniconda3\\envs\\FindOpenSimulationModels\\lib\\site-packages\\pandas\\core\\frame.py:621\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    619\u001b[0m     data \u001b[39m=\u001b[39m {}\n\u001b[0;32m    620\u001b[0m \u001b[39mif\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 621\u001b[0m     dtype \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_dtype(dtype)\n\u001b[0;32m    623\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, DataFrame):\n\u001b[0;32m    624\u001b[0m     data \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39m_mgr\n",
      "File \u001b[1;32mc:\\Users\\forre\\miniconda3\\envs\\FindOpenSimulationModels\\lib\\site-packages\\pandas\\core\\generic.py:450\u001b[0m, in \u001b[0;36mNDFrame._validate_dtype\u001b[1;34m(cls, dtype)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"validate the passed dtype\"\"\"\u001b[39;00m\n\u001b[0;32m    449\u001b[0m \u001b[39mif\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 450\u001b[0m     dtype \u001b[39m=\u001b[39m pandas_dtype(dtype)\n\u001b[0;32m    452\u001b[0m     \u001b[39m# a compound dtype\u001b[39;00m\n\u001b[0;32m    453\u001b[0m     \u001b[39mif\u001b[39;00m dtype\u001b[39m.\u001b[39mkind \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mV\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\forre\\miniconda3\\envs\\FindOpenSimulationModels\\lib\\site-packages\\pandas\\core\\dtypes\\common.py:1781\u001b[0m, in \u001b[0;36mpandas_dtype\u001b[1;34m(dtype)\u001b[0m\n\u001b[0;32m   1778\u001b[0m \u001b[39m# try a numpy dtype\u001b[39;00m\n\u001b[0;32m   1779\u001b[0m \u001b[39m# raise a consistent TypeError if failed\u001b[39;00m\n\u001b[0;32m   1780\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1781\u001b[0m     npdtype \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mdtype(dtype)\n\u001b[0;32m   1782\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mSyntaxError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m   1783\u001b[0m     \u001b[39m# np.dtype uses `eval` which can raise SyntaxError\u001b[39;00m\n\u001b[0;32m   1784\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdata type \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mdtype\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m not understood\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\forre\\miniconda3\\envs\\FindOpenSimulationModels\\lib\\site-packages\\numpy\\core\\_internal.py:61\u001b[0m, in \u001b[0;36m_usefields\u001b[1;34m(adict, align)\u001b[0m\n\u001b[0;32m     59\u001b[0m     names \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[39mif\u001b[39;00m names \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m---> 61\u001b[0m     names, formats, offsets, titles \u001b[39m=\u001b[39m _makenames_list(adict, align)\n\u001b[0;32m     62\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     63\u001b[0m     formats \u001b[39m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\forre\\miniconda3\\envs\\FindOpenSimulationModels\\lib\\site-packages\\numpy\\core\\_internal.py:29\u001b[0m, in \u001b[0;36m_makenames_list\u001b[1;34m(adict, align)\u001b[0m\n\u001b[0;32m     26\u001b[0m allfields \u001b[39m=\u001b[39m []\n\u001b[0;32m     28\u001b[0m \u001b[39mfor\u001b[39;00m fname, obj \u001b[39min\u001b[39;00m adict\u001b[39m.\u001b[39mitems():\n\u001b[1;32m---> 29\u001b[0m     n \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39;49m(obj)\n\u001b[0;32m     30\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(obj, \u001b[39mtuple\u001b[39m) \u001b[39mor\u001b[39;00m n \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m (\u001b[39m2\u001b[39m, \u001b[39m3\u001b[39m):\n\u001b[0;32m     31\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mentry not a 2- or 3- tuple\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'type' has no len()"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dtype = {\n",
    "    'Filename': 'string',\n",
    "    'Valid': 'boolean',\n",
    "    'Invalid Reason': 'string',\n",
    "    'FMI Version': 'string',\n",
    "    'Co-Simulation': 'boolean',\n",
    "    'Model Exchange': 'boolean',\n",
    "    'Param Count': 'Int64',\n",
    "    'Input Count': 'Int64',\n",
    "    'Output Count': 'Int64',\n",
    "    'Generation Tool': 'string'\n",
    "}\n",
    "df = pd.DataFrame(columns=dtype.keys(), dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'type' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m importlib\u001b[39m.\u001b[39mreload(AnalyzeFmuFiles) \u001b[39m# reload changes to AnalyzeFmuFiles.py every run\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m analyze \u001b[39m=\u001b[39m AnalyzeFmuFiles\u001b[39m.\u001b[39;49mAnalyzeFmuFiles(\u001b[39m'\u001b[39;49m\u001b[39mresults/downloads\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mresults/github-fmu-analysis.csv\u001b[39;49m\u001b[39m'\u001b[39;49m, is_testing)\n\u001b[0;32m      5\u001b[0m df \u001b[39m=\u001b[39m analyze\u001b[39m.\u001b[39manalyze()\n\u001b[0;32m      6\u001b[0m display(df)\n",
      "File \u001b[1;32mc:\\s\\FindOpenSimulationModels\\AnalyzeFmuFiles.py:95\u001b[0m, in \u001b[0;36mAnalyzeFmuFiles.__init__\u001b[1;34m(self, fmu_root_directory, results_filepath, is_testing)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, fmu_root_directory, results_filepath, is_testing\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m     94\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfmu_root_directory \u001b[39m=\u001b[39m fmu_root_directory\n\u001b[1;32m---> 95\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresult_store \u001b[39m=\u001b[39m ResultStore(results_filepath)\n\u001b[0;32m     96\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_testing \u001b[39m=\u001b[39m is_testing\n",
      "File \u001b[1;32mc:\\s\\FindOpenSimulationModels\\AnalyzeFmuFiles.py:43\u001b[0m, in \u001b[0;36mResultStore.__init__\u001b[1;34m(self, results_filepath)\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdf \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\n\u001b[0;32m     39\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults_filepath,\n\u001b[0;32m     40\u001b[0m         dtype \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdtype,\n\u001b[0;32m     41\u001b[0m         index_col \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mFilename\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     42\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 43\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdf \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mDataFrame(columns \u001b[39m=\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdtype\u001b[39m.\u001b[39;49mkeys(), dtype \u001b[39m=\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdtype)\n\u001b[0;32m     44\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdf\u001b[39m.\u001b[39mset_index(\u001b[39m'\u001b[39m\u001b[39mFilename\u001b[39m\u001b[39m'\u001b[39m, inplace \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     46\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalid_count \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\forre\\miniconda3\\envs\\FindOpenSimulationModels\\lib\\site-packages\\pandas\\core\\frame.py:621\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    619\u001b[0m     data \u001b[39m=\u001b[39m {}\n\u001b[0;32m    620\u001b[0m \u001b[39mif\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 621\u001b[0m     dtype \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_dtype(dtype)\n\u001b[0;32m    623\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, DataFrame):\n\u001b[0;32m    624\u001b[0m     data \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39m_mgr\n",
      "File \u001b[1;32mc:\\Users\\forre\\miniconda3\\envs\\FindOpenSimulationModels\\lib\\site-packages\\pandas\\core\\generic.py:450\u001b[0m, in \u001b[0;36mNDFrame._validate_dtype\u001b[1;34m(cls, dtype)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"validate the passed dtype\"\"\"\u001b[39;00m\n\u001b[0;32m    449\u001b[0m \u001b[39mif\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 450\u001b[0m     dtype \u001b[39m=\u001b[39m pandas_dtype(dtype)\n\u001b[0;32m    452\u001b[0m     \u001b[39m# a compound dtype\u001b[39;00m\n\u001b[0;32m    453\u001b[0m     \u001b[39mif\u001b[39;00m dtype\u001b[39m.\u001b[39mkind \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mV\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\forre\\miniconda3\\envs\\FindOpenSimulationModels\\lib\\site-packages\\pandas\\core\\dtypes\\common.py:1781\u001b[0m, in \u001b[0;36mpandas_dtype\u001b[1;34m(dtype)\u001b[0m\n\u001b[0;32m   1778\u001b[0m \u001b[39m# try a numpy dtype\u001b[39;00m\n\u001b[0;32m   1779\u001b[0m \u001b[39m# raise a consistent TypeError if failed\u001b[39;00m\n\u001b[0;32m   1780\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1781\u001b[0m     npdtype \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mdtype(dtype)\n\u001b[0;32m   1782\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mSyntaxError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m   1783\u001b[0m     \u001b[39m# np.dtype uses `eval` which can raise SyntaxError\u001b[39;00m\n\u001b[0;32m   1784\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdata type \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mdtype\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m not understood\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\forre\\miniconda3\\envs\\FindOpenSimulationModels\\lib\\site-packages\\numpy\\core\\_internal.py:61\u001b[0m, in \u001b[0;36m_usefields\u001b[1;34m(adict, align)\u001b[0m\n\u001b[0;32m     59\u001b[0m     names \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[39mif\u001b[39;00m names \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m---> 61\u001b[0m     names, formats, offsets, titles \u001b[39m=\u001b[39m _makenames_list(adict, align)\n\u001b[0;32m     62\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     63\u001b[0m     formats \u001b[39m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\forre\\miniconda3\\envs\\FindOpenSimulationModels\\lib\\site-packages\\numpy\\core\\_internal.py:29\u001b[0m, in \u001b[0;36m_makenames_list\u001b[1;34m(adict, align)\u001b[0m\n\u001b[0;32m     26\u001b[0m allfields \u001b[39m=\u001b[39m []\n\u001b[0;32m     28\u001b[0m \u001b[39mfor\u001b[39;00m fname, obj \u001b[39min\u001b[39;00m adict\u001b[39m.\u001b[39mitems():\n\u001b[1;32m---> 29\u001b[0m     n \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39;49m(obj)\n\u001b[0;32m     30\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(obj, \u001b[39mtuple\u001b[39m) \u001b[39mor\u001b[39;00m n \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m (\u001b[39m2\u001b[39m, \u001b[39m3\u001b[39m):\n\u001b[0;32m     31\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mentry not a 2- or 3- tuple\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'type' has no len()"
     ]
    }
   ],
   "source": [
    "import AnalyzeFmuFiles\n",
    "importlib.reload(AnalyzeFmuFiles) # reload changes to AnalyzeFmuFiles.py every run\n",
    "import pandas\n",
    "analyze = AnalyzeFmuFiles.AnalyzeFmuFiles('results/downloads', 'results/github-fmu-analysis.csv', is_testing)\n",
    "df = analyze.analyze()\n",
    "display(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Future Work\n",
    "\n",
    "- Security note: Executable code in FMU files should be treated as untrusted!\n",
    "- Statistics about FMUs (# params/inputs/outputs, OS platforms)\n",
    "- Take a closer looks at a sampling of FMUs to see if they can be understood and controlled to achieve some sort of objective\n",
    "- How to handle versioning of FMU files? The URLs are https://github.com/{username}/{repository}/blob/{commit_hash}/{file_path}. We could eventually have multiple commit hashes for different versions of the same file. Should we keep them all? Or just the latest? Also note that branch name could be used instead of commit_hash to reference the latest version in a branch. Perhaps we should convert the commit hashes to reference the latest version in the default branch?\n",
    "- There are many [limitations on GitHub code search](https://docs.github.com/en/search-github/searching-on-github/searching-code#considerations-for-code-search). What would be a better way to find files on GitHub. An archive or crawler?\n",
    "- Other file types (Modelica, MATLAB, ...?)\n",
    "- Internet search (files outside GitHub)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FindOpenSimulationModels",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8ee1e9661fac7e11d052fa47f33767e1ae2c17c62148570d01dc46b81a3f0767"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
